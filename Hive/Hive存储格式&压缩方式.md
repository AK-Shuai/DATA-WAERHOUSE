## Hive表的存储格式
<div align=center><img src="https://raw.githubusercontent.com/shuainuo/DATA-WAERHOUSE/main/%E5%9B%BE%E5%BA%8A/Hive%E5%8E%8B%E7%BC%A9%E6%A0%BC%E5%BC%8F.png" width="400"></div>
Hive支持的表类型，或者称为存储格式有：TextFile、SequenceFile、RCFile、ORC、Parquet、AVRO。  

### RCFile、ORC、Parquet  
RCFile、ORC、Parquet这三种格式，均为列式存储表——准确来说，应该是行、列存储相结合。在存储时，首先会按照行数进行切分，切分为不同的数据块进行存储，也就是行存储；在每一个数据块中，存储时使用的又是列式存储，将表的每一列数据存放在一起。这种列式存储在大数据技术中尤为常见，它在海量数据场景中是很好的一种优化手段，可以减少数据读取、移动所花费的时间；因为在结构化数据处理中，一般不会用到全部数据，而是选择某几列进行运算，使用行式存储会将所有数据加载后再进行过滤，而列式存储可以只读取这几列数据，减少数据读取、处理所需要的时间，这在海量数据场景中可以节约非常多的时间。

列式存储表中，RCFile现在基本很少使用了，它是ORC表的前身，支持的功能和计算性能都低于ORC表。

ORC表是Hive计算的主要表形式，是在RCFile的基础上进行了优化和改进，支持NONE、Zlib、Snappy压缩，在分析计算中的性能较好，是生产中常见的表类型。而且ORC表可以开启事务功能，以便支持数据更新、删除等操作，但事务的开启会影响表的处理性能，所以非必要情况下不需要启用事务功能。但ORC表的问题在于，它是Hive特有的存储类型，所以在其它大数据产品中兼容性并不好，有些只有在较高的版本中才会支持。

Parquet表也是Hive计算的主要表形式，它的计算性能稍弱于ORC表，但因为Parquet文件是Hadoop通用的存储格式，所以对于其它大数据组件而言，具有非常好的数据兼容度；而且Parquet表可以支持数据的多重嵌套（如JSON的属性值可以是一个对象，且支持嵌套），但ORC表在多重嵌套上的性能并不好。Parquet支持uncompressed\snappy\gzip\lzo压缩，其中lzo压缩方式压缩的文件支持切片，意味着在单个文件较大的场景中，处理的并发度会更高；而ORC表的压缩方式不支持切分，如果单个压缩文件较大的话，性能会有影响。

所以，对于ORC表和Parquet表的选择要区分使用场景，如果只在Hive中处理时使用，追求更高效的处理性能，且单个文件不是很大，或者需要有事务的支持，则选用ORC表。但如果要考虑到与其它大数据产品的兼容度，且单个文件较为庞大，数据存在多重嵌套，则选用Parquet表。

### AVRO

最后AVRO表，它主要为 Hadoop 提供数据序列化和数据交换服务，支持二进制序列化方式，它与Thrift功能类似。一般而言，在数据传输中，不会直接将文本发送出去，而是先要经过序列化，然后再进行网络传输，AVRO就是Hadoop中通用的序列化和数据交换标准。所以，如果数据通过其他Hadoop组件使用AVRO方式传输而来，或者Hive中的数据需要便捷的传输到其他组件中，使用AVRO表是一种不错的选择。
### 压缩方式
Hive内置的压缩方式有bzip2、deflate、gzip，支持的第三方压缩方式有lzo、snappy。标准压缩方式为deflate，其算法实现是zlib。  

其中bzip2、lzo支持压缩后文件再拆分。  

对于这几种压缩算法，按照压缩比的排名顺序为：bzip2 > gzip > deflate > snappy > lzo。所以如果想保证高压缩率，那可以选用bzip2、gzip，但相应的压缩/解压缩的时间也会很长。相反的，按照压缩/解压缩耗时排名，顺序正好相反：lzo < snappy < deflate < gzip < bzip2，所以如果追求处理效率，则可以使用lzo、snappy进行压缩。